# Strata – Positioning & Differentiation (v0.1)

## 1. Summary

**Thesis:**
The “AI over your files” baseline is already commoditized: connectors to SMB/NFS, ACL-aware indexing, and a chat UI over PDFs/Office docs are all shipping from storage vendors (NetApp/Egnyte), file-access platforms (FileOrbis, Triofox), and generic “internal GPT” tools.

**Strata cannot just be another AI assistant over file shares.**

Instead, Strata positions itself as:

> **The semantic and safety data plane for AI over your file estate** – a headless engine that gives all your copilots a high-fidelity, policy-aware view of your documents, with built-in observability and evaluation.

We target **platform teams and vendors** who need a **programmable layer**, not an end-user assistant.

---

## 2. Market Context

Common promise across FileOrbis / Triofox / NetApp+Q / Egnyte / Olympus / generic internal GPTs:

* Connect to SMB/NFS/file servers and cloud file systems.
* Keep an index in sync (often near real time).
* Enforce AD/ACL permissions at retrieval.
* Provide chat/Q&A and search over internal docs.
* Log queries for audit/compliance.

Security and backup vendors (Varonis, CrashPlan, Cohesity, etc.) are converging from another direction:

* Discover and classify sensitive data on file shares and M365.
* Monitor AI tools (e.g., Copilot) for sensitive data leakage.
* Provide least-privilege and abnormal usage detection.

To a buyer, this is a crowded “safe AI over unstructured data” category.

---

## 3. Target Customer & ICP

**Primary ICP (near/mid-term)**

* Internal **AI platform / infra teams** in mid-to-large enterprises.
* SaaS vendors (storage, collaboration, vertical apps) who want to embed advanced “AI over files” capabilities without building the pipeline themselves.

**Key characteristics:**

* Already experimenting with Copilot / Amazon Q / ChatGPT Enterprise or building internal assistants.
* Have meaningful file estates (SMB/NFS, object, SharePoint, etc.).
* Care about **governance, correctness, and evaluation**, not just “we turned on AI.”

We’re *not* initially targeting:

* SMBs looking for a turn-key AI assistant.
* End-user-centric “knowledge copilots” competing directly with existing UIs.

---

## 4. Product Definition (what Strata is)

**Strata is a headless, API-first semantic and safety layer for documents.**

Core capabilities (directionally):

1. **Connectors & Ingestion** – pull file content + ACLs into a normalized model.
2. **Semantics** – type-aware chunking, entity extraction, cross-document graph, semantic diff.
3. **Policy Engine** – programmable rules for what *any* agent is allowed to see and how (raw vs redacted vs summarized).
4. **RAG Observability & Evaluation** – instrumentation and tests for retrieval quality, answer coverage, and safety.
5. **APIs & SDKs** – primitives like `search_chunks`, `semantic_diff`, `answer_with_evidence`, `evaluate_rag_pipeline`, `get_retrieval_trace`.

We explicitly **do not** position as:

* A file gateway.
* A storage product.
* A primary chat UI or “Copilot replacement.”

---

## 5. Differentiation Pillars

### 5.1 Infra, not yet another assistant (developer-first)

**Others:**
FileOrbis, Triofox, NetApp+Q, Egnyte, Olympus all bundle:

* Connectors + indexing
* Chat/search UI
* Some configurability of RAG pipeline

They sell **solutions** (AI assistants, collaboration portals), not infra.

**Strata:**

* Ships as **APIs, SDKs, and services** that platform teams integrate into:

  * MS Copilot plugins
  * Amazon Q data sources
  * Custom assistants (Slack bots, ServiceNow actions, internal web apps)
* Minimal “demo UI” purely for debugging; not the core product.
* Designed to be deployed alongside internal LLM stacks, not as a replacement.

**Why this matters:**

* We can be embedded by vendors (including storage/file vendors) without competing with their UI.
* We focus on solving the hardest infra problems (semantics, policy, evaluation) instead of UI/features arms race.

---

### 5.2 Deep semantics & change intelligence, not just RAG plumbing

**Others:**

* Talk about “RAG” and “hybrid search,” but primarily at the level of documents + chunks.
* Little emphasis on doc-type semantics, cross-document relationships, or semantic diff.

**Strata:**

* Treats specific doc types as first-class: contracts, SOWs, policies, engineering RFCs, runbooks.
* Extracts **structured fields** (parties, terms, controls, decisions, owners, milestones).
* Builds a **lightweight knowledge graph**: customers/projects ↔ contracts ↔ SOWs ↔ policies ↔ RFCs.
* Supports **semantic versioning**:

  * Diff contracts/SOWs/policies between versions in terms of obligations and parameters.
  * Generate periodic “change reports” per project/customer/folder.

**Why this matters:**

* Unlocks high-value use cases: contract change radar, policy change tracking, engineering design drift, etc.
* Moves us beyond “search & chat” into **operational knowledge workflows**.

---

### 5.3 RAG observability & evaluation as first-class

**Others:**

* Provide logging/audit of queries and data access (for compliance).
* Little to no positioning around **measuring** retrieval/answer quality or debugging pipelines.

**Strata:**

* Treats each AI interaction as an observable event:

  * Questions, retrieved chunks, ranking scores.
  * Per-sentence evidence mapping.
  * Sensitivity/ACL state at answer time.

* Provides **out-of-the-box evaluation**:

  * Auto-generated test suites per corpus (Q&A pairs).
  * Metrics: recall@k, answer coverage, hallucination risk, sensitivity exposure.
  * Regression testing when content, ACLs, or models change.

**Why this matters:**

* Platform teams need to *operate* RAG over files like they operate services: with dashboards, alerts, and tests.
* Gives a clear story for “enterprise readiness” and continuous improvement.

---

### 5.4 Policy engine & “LLM-safe views,” not just ACL mirroring

**Others:**

* Emphasize enforcing existing ACLs and respecting AD/groups.
* Some, like Varonis, add sensitive data detection and Copilot-specific controls.

**Strata:**

* Adds a **declarative policy layer** on top of ACLs, driven by semantics:

  * e.g., “Any external agent can only see content tagged `public` or `customer-facing`.”
  * “Legal assistant may see all `contract` docs regardless of file ACL, but not `HR` docs.”
  * “No agent may surface unmasked SSNs or card numbers.”

* Implements **LLM-specific views** per chunk:

  * `raw_chunk`, `redacted_chunk`, `masked_chunk`, `summary_chunk`.
  * Retrieval returns the appropriate view based on agent identity and policy.

**Why this matters:**

* Large organizations want **centralized, programmable control** over AI’s visibility.
* This is the missing piece between “storage permissions” and “safe AI behavior.”

---

## 6. Strategic Boundaries

To stay differentiated and avoid getting dragged into commodity territory:

1. **We do NOT build:**

   * A full-featured end-user chat/collaboration product.
   * Another general-purpose “internal GPT” with dozens of app connectors.
   * A core storage platform or file gateway.

2. **We DO focus on:**

   * A clean, powerful **semantic and policy model** over files.
   * High-quality APIs and SDKs for platform teams.
   * Strong RAG observability/evaluation story.
   * A few deep vertical semantics (e.g., contracts/policies/RFCs) where we can show 10x value.

---

## 7. Positioning Statements

**Tagline options:**

* “The semantic and safety data plane for AI over your files.”
* “Give every copilot the same governed, high-fidelity view of your documents.”
* “From file shares to provable, policy-safe AI answers.”

**One-line pitch:**

> Strata is a headless semantic and safety layer that sits between your file estate and your AI assistants, giving them a high-fidelity, policy-aware view of your documents — with observability and evaluation built in.

**Short paragraph:**

> Most vendors will happily “turn on AI” for your file shares, but they stop at indexing and ACLs. Strata goes deeper: it models the actual semantics of your contracts, policies, and technical docs; enforces programmable policies and LLM-safe views across assistants; and gives your platform team the tools to measure and debug every answer. It’s not another chatbot – it’s the semantic and safety data plane that all your copilots share.

---

# Strata v0 Product Spec – Semantic & Safety Data Plane

Version: 0.1 (draft)

## 1. Objective & Non-Objectives

### Objective

Build a **deployable v0** that:

* Demonstrates Strata as a **headless semantic & safety layer**, not a chat UI.
* Solves real problems for 1–2 design partners around:

  * Semantic understanding of **contracts/policies/RFCs**, and
  * **RAG observability** + basic policy controls for assistants over those docs.
* Exposes a clear, opinionated **API surface** that app/assistant teams can adopt.

### Non-Objectives (v0)

* No multi-tenant control plane or full SaaS UX.
* No broad connector zoo (we’ll start with a narrow set).
* No full-blown end-user assistant product.
* No complex policy language UI – start with configuration-as-code.

---

## 2. Personas & Core Use Cases

### Personas

1. **AI Platform / Developer Experience Lead**

   * Owns internal LLM stack and integrations.
   * Wants standard APIs to access documents with semantics and policies enforced.
   * Needs observability and tests.

2. **Security / Compliance Architect**

   * Worried about sensitive data flowing into assistants.
   * Wants assurance and auditability around what AI can see and say.

3. **Application/Assistant Team (Line-of-Business)**

   * Building a specific assistant: “Contract Copilot”, “Policy Copilot”, “Engineering Doc Copilot”.
   * Wants to consume semantic/search APIs without implementing ingestion, parsing, ACL mapping, etc.

### Initial Use Cases

1. **Semantic Q&A with Evidence Over Contracts/Policies/RFCs**

   * Input: question + user identity + scope (e.g., folder/project).
   * Output: answer + exact supporting clauses/sections + evidence coverage score.
   * Constraints: only content allowed by ACLs + Strata policy; optional redaction.

2. **Semantic Diff & Change Reports**

   * Diff two versions of a contract/policy/RFC.
   * Generate a periodic report: “What changed in these documents over the last week?”

3. **RAG Observability & Debugging**

   * For any assistant call that uses Strata:

     * Log query, retrieval trace, selected chunks, sensitivity labels, answer summary.
     * Expose this trace via API / debug UI.

4. **Basic Policy Enforcement / LLM-safe Views**

   * Simple policies like:

     * “Strip PII from outputs for assistant X.”
     * “Assistant Y can only see documents tagged `doc_type=policy`.”
   * Enforced at retrieval time via views (redacted/masked/summarized).

---

## 3. Scope & Features (v0)

### 3.1 Connectors & Ingestion

**v0 Scope:**

* **Single-tenant** deployment.
* One or two storage backends:

  * SMB share (read-only view).
  * Or S3-compatible bucket (simpler if you want to start with “drop files here”).
* ACL ingestion:

  * For SMB: map NTFS/AD ACLs to an internal principal model (user, groups).
  * For S3: bucket-level or prefix-level access config via config file.

**Features:**

* Batch ingestion job + incremental change detection:

  * For v0, incremental can be a periodic re-scan with content-hash checks (not fully event-based).
* Store:

  * File metadata (path, size, timestamps).
  * Version info (simple: treat updates as new versions with content hash).

### 3.2 Parsing & Normalization

**Document types (v0):**

* PDF, DOCX for contracts and policies.
* Markdown / plain text for engineering docs/RFCs.

**Outputs:**

* Per-document normalized representation:

  * Text blocks with page/section info.
  * Heading hierarchy where possible.
  * Basic table detection (best-effort, not perfect).
* Unified schema with:

  * `document_id`, `version_id`, `path`, `tenant_id` (placeholder for future), `mime_type`.
  * `blocks[]` (with `text`, `section_path`, `page`, `position`).

### 3.3 Chunking & Embeddings

**Chunking (v0):**

* Type-aware but simple:

  * Contracts/policies:

    * Chunk by clauses/sections using heading + numbering heuristics.
  * RFCs/engineering docs:

    * Chunk by headings and paragraphs, maintain `section_path`.

* Target chunk size: ~300–600 tokens.

**Embeddings:**

* Single general-purpose embedding per chunk.
* Stored in a vector index (you choose implementation: pgvector, Qdrant, etc.).

### 3.4 Semantics & Extraction (Narrow but Deep)

**v0 focus doc types:**

* **Contracts / SOW-like docs**
* **Policies**
* **Engineering RFCs / design docs**

**Semantic extraction (MVP):**

* **Contracts/SOWs/Policies:**

  * Parties
  * Effective date
  * Term and renewal
  * Governing law (if present)
  * High-level obligations/sections (e.g., payment, SLA, termination)

* **RFCs/Design Docs:**

  * Title, owner, status
  * Affected systems/services
  * Decision summary

Implementation: LLM-based extractors with per-type JSON schemas; results stored as `structured_fields` per document.

**Semantic Diff (v0):**

* Given `document_id` + two `version_ids`:

  * Compare `structured_fields` and highlight field-level changes.
  * Identify added/removed/changed sections by section heading.
  * Output a machine-readable diff plus a natural-language summary.

### 3.5 Policy Engine & LLM-Safe Views

**Policy representation (v0):**

* Config-as-code (YAML/JSON) defining rules like:

  ```yaml
  policies:
    - id: "external_assistant"
      applies_to_agents: ["external_assistant"]
      visibility:
        include_doc_types: ["policy", "faq"]
        exclude_doc_types: ["contract", "hr"]
      redaction:
        mask_pii: true
    - id: "legal_assistant"
      applies_to_agents: ["legal_assistant"]
      visibility:
        include_doc_types: ["contract", "policy"]
      redaction:
        mask_pii: false
  ```

**LLM-safe views:**

* For each chunk, Strata can expose:

  * `raw_text`
  * `redacted_text` (PII masked via regex/LLM-based detection)
  * (Optional) `summary_text` (short bullet summary of the chunk)

**Enforcement path:**

* Agent calls Strata with `agent_id` and `user_id`:

  * Strata resolves ACL (based on `user_id`) and policy (based on `agent_id`).
  * Filters eligible documents/chunks.
  * Returns view text (`raw` vs `redacted`) accordingly.

### 3.6 RAG Observability & Traceability

**Data captured per call:**

* Query details:

  * `agent_id`, `user_id`, timestamp.
  * Original question.
  * Scope (folders/doc types).

* Retrieval trace:

  * Pre-filtered candidates (doc ids, scores).
  * Final chunk list with scores.
  * For each chunk: sensitivity labels, doc_type, path, version.

* Answer instrumentation (if Strata is used for synthesis):

  * Answer text.
  * Mapping from answer sentences to supporting chunks (rough LLM-based alignment).
  * Evidence coverage score (e.g., 0–1 scale).

**APIs:**

* `get_trace(interaction_id)` → full trace JSON.
* `list_interactions(filters)` → paginated list of interactions for dashboards.

### 3.7 APIs / Developer Surface (v0)

Key external APIs (REST/JSON; GraphQL or gRPC later if desired):

1. `POST /v0/search_chunks`

   * Input: `query`, `user_id`, `agent_id`, optional filters (doc_type, path).
   * Output: ranked chunks with view text (policy+ACL enforced), metadata, scores.

2. `POST /v0/answer_with_evidence` (optional v0; can be a thin wrapper around `search_chunks` + your LLM)

   * Input: `question`, `user_id`, `agent_id`, scope.
   * Output: `answer`, list of supporting chunks, evidence coverage, `interaction_id`.

3. `POST /v0/semantic_diff`

   * Input: `document_id`, `from_version`, `to_version`.
   * Output: structured diff + natural-language summary.

4. `GET /v0/traces/{interaction_id}`

   * Input: `interaction_id`.
   * Output: full retrieval/answer trace.

5. `POST /v0/evaluate_rag` (stretch goal)

   * Input: set of (question, reference_answer, scope).
   * Output: metrics (retrieval recall, answer quality scores).

---

## 4. Architecture Overview (v0)

High-level components:

1. **Ingestion Service**

   * Scans configured storage (SMB/S3).
   * Computes content hashes and version IDs.
   * Writes records to a persistent store (e.g., Postgres) and pushes “doc updated” events.

2. **Parsing & Semantics Worker**

   * Consumes “doc updated” events.
   * Extracts text, structure, and sections.
   * Does type classification (contract / policy / RFC / other).
   * Runs semantic extractors (LLM calls) for supported types.
   * Produces chunks + embeddings + structured fields.

3. **Index & Metadata Store**

   * Relational DB (Postgres) for documents, versions, chunks, ACLs, structured fields.
   * Vector index (pgvector/Qdrant/etc.) for embeddings.

4. **Policy & ACL Engine**

   * Resolves `user_id` → effective groups/roles.
   * Applies file ACL filters + policy filters.
   * Decides which view (raw/redacted) to use.

5. **API Gateway**

   * Hosts `/search_chunks`, `/answer_with_evidence`, `/semantic_diff`, `/traces`, `/evaluate_rag`.
   * Applies authN/authZ at request level.

6. **Observability & Trace Store**

   * Stores interaction logs and traces.
   * Basic metrics aggregation for v0 (query volume, latency, etc.).

---

## 5. Deployment Model (v0)

For design partners, prioritize:

* **Single-tenant, customer VPC deployment** (Kubernetes or VM-based)
  OR
* **Single-tenant cloud instance** in your own cloud account, logically isolated.

Characteristics:

* Config via environment variables and config-as-code.
* Basic metrics via Prometheus/OpenTelemetry.
* No multi-tenant control plane yet.

---

## 6. Success Criteria

### Qualitative

* At least one design partner’s assistant (e.g., “Contract Copilot” or “Policy Copilot”) uses Strata as its primary document layer.
* That partner can:

  * Debug RAG behavior using traces.
  * Show semantic diffs of key documents.
  * Enforce at least one non-trivial policy via Strata (e.g., redaction for external assistant).

### Quantitative (targets)

* Retrieval latency (P95) under 500–800 ms for `search_chunks` given index of ~100k–500k chunks.
* In internal tests, Strata’s retrieval + semantics pipeline yields:

  * Measurably higher evidence coverage vs naive chunk+vector (you can show this with small benchmarks).
* At least **2–3 concrete “wow moments”** in user demos:

  * e.g., “Show me what changed in our ACME contracts this quarter,” with a semantic report and evidences.
